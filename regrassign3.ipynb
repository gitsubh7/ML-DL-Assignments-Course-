{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1435926-1055-49b0-97c1-8200148d2e03",
   "metadata": {},
   "source": [
    "## Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f5de54-105f-45b8-b96e-432b6088c069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRidge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67c5f65-69b9-4adb-9e93-9011702a288a",
   "metadata": {},
   "source": [
    "## Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e4a5222-aa2b-4676-9076-a18607ce8aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14a0cd-bda3-42ca-bd06-8f4f921fe90e",
   "metadata": {},
   "source": [
    "## Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23513ed6-c4ff-4ee2-ab1e-333edde7048d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn one of our articles, we have seen that ridge regression is used to get rid of overfitting which can also be reduced by fitting the model with only important features. Ridge regression can also help us in feature selection to find out the important features required for modelling purposes.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In one of our articles, we have seen that ridge regression is used to get rid of overfitting which can also be reduced by fitting the model with only important features. Ridge regression can also help us in feature selection to find out the important features required for modelling purposes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840ab2c-02a6-4150-9b80-57b2092640bc",
   "metadata": {},
   "source": [
    "## Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e66ca02f-8ebb-4c31-9d33-f3170193e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe have seen that ridge regression is used to get rid of overfitting which can also be reduced by fitting the model with only important features. Ridge regression can also help us in feature selection to find out the important features required for modelling purposes\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we have seen that ridge regression is used to get rid of overfitting which can also be reduced by fitting the model with only important features. Ridge regression can also help us in feature selection to find out the important features required for modelling purposes\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a72fd29-17b4-4b2f-a571-631a6740981b",
   "metadata": {},
   "source": [
    "## Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d58785e2-c46e-4c6d-a58c-2c672afa9a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMulticollinearity happens when predictor variables exhibit a correlation among themselves. Ridge regression aims at reducing the standard error by adding some bias in the estimates of the regression. The reduction of the standard error in regression estimates significantly increases the reliability of the estimates.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Multicollinearity happens when predictor variables exhibit a correlation among themselves. Ridge regression aims at reducing the standard error by adding some bias in the estimates of the regression. The reduction of the standard error in regression estimates significantly increases the reliability of the estimates.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31453cb-0715-4afd-908a-a28ffd1af581",
   "metadata": {},
   "source": [
    "## Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb1ab885-d2d0-496b-815e-d04162bc629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are correct to assume that a categorical variable is encoded as indicator function/vector in your design matrix X\\n; this is standard. To that respect, usually one of the levels is omitted and subsequently treated as baseline (if not you would have surely a rank-deficient design matrix when incorporating an intercept'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "You are correct to assume that a categorical variable is encoded as indicator function/vector in your design matrix X\n",
    "; this is standard. To that respect, usually one of the levels is omitted and subsequently treated as baseline (if not you would have surely a rank-deficient design matrix when incorporating an intercept'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3381011-f1ca-4d90-9b56-1f73056ae598",
   "metadata": {},
   "source": [
    "## Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907c362-4572-4434-aeb2-5e27897f9fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
