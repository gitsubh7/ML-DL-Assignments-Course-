{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3421a5d3-b78e-4c4f-b62a-23eb9be6d752",
   "metadata": {},
   "source": [
    "## What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a395516f-4fa4-4d60-93ec-5ee6858b3afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlastic net regression is a linear regression technique that uses a penalty term to shrink the coefficients of the predictors. The penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients, weighted by a parameter called alpha.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lastic net regression is a linear regression technique that uses a penalty term to shrink the coefficients of the predictors. The penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients, weighted by a parameter called alpha.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d197b-637b-441b-8c1a-d34c1e91110a",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2990335-6cb1-46b6-91a3-131c0258c6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe regularization term (also called the penalty term) can take different forms that will be discussed soon in this post.\\n\\nA linear regression model that predicts continuous-valued outputs learns the optimal values for its coefficients by minimizing its loss function. The same thing applies to a logistic regression model that predicts discrete-valued outputs. In both cases, we can apply regularization during the model training phase.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The regularization term (also called the penalty term) can take different forms that will be discussed soon in this post.\n",
    "\n",
    "A linear regression model that predicts continuous-valued outputs learns the optimal values for its coefficients by minimizing its loss function. The same thing applies to a logistic regression model that predicts discrete-valued outputs. In both cases, we can apply regularization during the model training phase.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee629a2-af5e-48fb-a1a3-11b6fb00efe1",
   "metadata": {},
   "source": [
    "## Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865c5f37-6bf2-460a-9142-990d83c09530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIt doesn't have the problem of selecting more than n predictors when p≫n. Whereas lasso saturates when p≫n.\\n\\nWhen there are highly correlated predictors lasso tends to just pick one predictor out of the group.\\n\\nWhen n≫p and the predictors are correlated, the prediction performance of lasso is smaller than that of ridge.\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "It doesn't have the problem of selecting more than n predictors when p≫n. Whereas lasso saturates when p≫n.\n",
    "\n",
    "When there are highly correlated predictors lasso tends to just pick one predictor out of the group.\n",
    "\n",
    "When n≫p and the predictors are correlated, the prediction performance of lasso is smaller than that of ridge.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddf59b-c42b-43de-99b7-631fc1c492af",
   "metadata": {},
   "source": [
    "## Q4. What are some common use cases for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7961f04a-2b92-4240-bbc6-ff0b1309a18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nElastic net is appropriate when the variables form groups that contain highly correlated independent variables. Variable selection is incorporated into the model-building procedure to aid in raising the accuracy\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Elastic net is appropriate when the variables form groups that contain highly correlated independent variables. Variable selection is incorporated into the model-building procedure to aid in raising the accuracy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197647c9-db0b-44b0-aaa9-289a8286bea6",
   "metadata": {},
   "source": [
    "## Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56ea063-204b-410d-b5fd-04bdbf3457f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhile you no longer have to collect data on the variables who coefficients are estimated as zero, eliminating those variables and refitting will (or at least can) change the other coefficient estimates. During the minimization of the LASSO loss function, the features that wind up \"dead\" still contribute by setting their coefficients to be zero.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "While you no longer have to collect data on the variables who coefficients are estimated as zero, eliminating those variables and refitting will (or at least can) change the other coefficient estimates. During the minimization of the LASSO loss function, the features that wind up \"dead\" still contribute by setting their coefficients to be zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c71cfa7-2676-4ba7-a8be-b8b0c4543f44",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values when using Elastic Net Regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55fd9c3b-9a7d-4cb8-93e6-933c7d4bcf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDeleting Rows with missing values\\nImpute missing values for continuous variable\\nImpute missing values for categorical variable\\nOther Imputation Methods\\nUsing Algorithms that support missing values\\nPrediction of missing values\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Deleting Rows with missing values\n",
    "Impute missing values for continuous variable\n",
    "Impute missing values for categorical variable\n",
    "Other Imputation Methods\n",
    "Using Algorithms that support missing values\n",
    "Prediction of missing values\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf77e5c-9337-48e0-abbf-eb57609f9a00",
   "metadata": {},
   "source": [
    "## Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a3d0-f581-4d44-8a09-6aaf81e1c394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
