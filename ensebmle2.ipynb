{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab037dcd-10be-497b-b854-3a92f566a560",
   "metadata": {},
   "source": [
    "## Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa30dc9-f967-4151-8829-d882b43b8c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe will look at the information gain for that feature across all trees. Then average the information gain for that feature across all trees. Advantages of bagging-decision trees. The variance of the model is reduced. Multiple trees can be trained simultaneously. Problem with bagging-decision trees.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We will look at the information gain for that feature across all trees. Then average the information gain for that feature across all trees. Advantages of bagging-decision trees. The variance of the model is reduced. Multiple trees can be trained simultaneously. Problem with bagging-decision trees.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab09ccd-9a5c-440e-a4d6-fc5a17d3ffab",
   "metadata": {},
   "source": [
    "## Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7421876f-05c8-40ed-a6d8-79c09edc675b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe bias-variance trade-off is a challenge we all face while training machine learning algorithms. Bagging is a powerful ensemble method which helps to reduce variance, and by extension, prevent overfitting. Ensemble methods improve model precision by using a group (or \"ensemble\") of models which, when combined, outperform individual models ...\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The bias-variance trade-off is a challenge we all face while training machine learning algorithms. Bagging is a powerful ensemble method which helps to reduce variance, and by extension, prevent overfitting. Ensemble methods improve model precision by using a group (or \"ensemble\") of models which, when combined, outperform individual models ...\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9397c-5318-415d-a4db-5c14ec54268c",
   "metadata": {},
   "source": [
    "## Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f28810b-8a5d-419b-97f4-1ee796ffc9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBias Variance Tradeoff is a design consideration when training the machine learning model. Certain algorithms inherently have a high bias and low variance and vice-versa. In this one, the concept of bias-variance tradeoff is clearly explained so you make an informed decision when training your ML models.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Bias Variance Tradeoff is a design consideration when training the machine learning model. Certain algorithms inherently have a high bias and low variance and vice-versa. In this one, the concept of bias-variance tradeoff is clearly explained so you make an informed decision when training your ML models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb8f80-6e7f-4c72-bddf-f0312959d555",
   "metadata": {},
   "source": [
    "## Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f507385-ea9f-440f-903e-4f87bdfd1308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBoth methods can be used for classification task 2.Random Forest is use for classification whereas Gradient Boosting is use for regression task 3. Random Forest is use for regression whereas Gradient Boosting is use for Classification task 4. Both methods can be used for regression task \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Both methods can be used for classification task 2.Random Forest is use for classification whereas Gradient Boosting is use for regression task 3. Random Forest is use for regression whereas Gradient Boosting is use for Classification task 4. Both methods can be used for regression task \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd696b2-582d-41f7-9fd7-ee8c25cb3462",
   "metadata": {},
   "source": [
    "## Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d50a91e-66f3-4730-b1f0-35ae7b9571c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnsemble learning is a machine learning paradigm where multiple models (often called “weak learners”) are trained to solve the same problem and combined to get better results. The main hypothesis is that when weak models are correctly combined we can obtain more accurate and/or robust models. Single weak learner\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Ensemble learning is a machine learning paradigm where multiple models (often called “weak learners”) are trained to solve the same problem and combined to get better results. The main hypothesis is that when weak models are correctly combined we can obtain more accurate and/or robust models. Single weak learner\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7efbb-7370-409f-adfc-dbedd091c0d1",
   "metadata": {},
   "source": [
    "## Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3bbda-776d-463b-b29e-cfd19e98353f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
