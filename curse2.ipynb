{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3732a6-bab6-45ca-8b79-af5c831082c7",
   "metadata": {},
   "source": [
    "## Q1. What is a projection and how is it used in PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6672af13-8df3-4335-9fa3-750f4034eeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis paper introduces a Projected Principal Component Analysis (Projected-PCA), which employees principal component analysis to the projected (smoothed) data matrix onto a given linear space spanned by covariates. When it applies to high-dimensional factor analysis, the projection removes noise components.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This paper introduces a Projected Principal Component Analysis (Projected-PCA), which employees principal component analysis to the projected (smoothed) data matrix onto a given linear space spanned by covariates. When it applies to high-dimensional factor analysis, the projection removes noise components.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a659cf03-f51d-48cf-869c-bafea4358d28",
   "metadata": {},
   "source": [
    "## Q2. How does the optimization problem in PCA work, and what is it trying to achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487b2c92-d112-4025-8198-a6e78171f76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA can be used to reduce the dimensionality of the data by creating a set of derived variables that are linear combinations of the original variables. The values of the derived variables are given in the columns of the scores matrix Z\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PCA can be used to reduce the dimensionality of the data by creating a set of derived variables that are linear combinations of the original variables. The values of the derived variables are given in the columns of the scores matrix Z\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586de30-fcf5-4997-8726-c7d781a60d3a",
   "metadata": {},
   "source": [
    "## Q3. What is the relationship between covariance matrices and PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a0fe75-f5f8-46d1-b328-c04860c5e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA is simply described as “diagonalizing the covariance matrix”. What does diagonalizing a matrix mean in this context? It simply means that we need to find a non-trivial linear combination of our original variables such that the covariance matrix is diagonal\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PCA is simply described as “diagonalizing the covariance matrix”. What does diagonalizing a matrix mean in this context? It simply means that we need to find a non-trivial linear combination of our original variables such that the covariance matrix is diagonal\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ac5bd-582f-4e8c-9e91-f88a4d21ef78",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of number of principal components impact the performance of PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0aa264-5465-4787-a90c-364887db6a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA widely applied approach is to decide on the number of principal components by examining a scree plot. By eyeballing the scree plot, and looking for a point at which the proportion of variance explained by each subsequent principal component drops off. This is often referred to as an elbow in the scree plo\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A widely applied approach is to decide on the number of principal components by examining a scree plot. By eyeballing the scree plot, and looking for a point at which the proportion of variance explained by each subsequent principal component drops off. This is often referred to as an elbow in the scree plo\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de45fd-3157-49e5-903f-b799e19f1005",
   "metadata": {},
   "source": [
    "## Q5. How can PCA be used in feature selection, and what are the benefits of using it for this purpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c7b578-c44d-4f4f-94b4-21f22b323b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The only way PCA is a valid method of feature selection is if the most important variables are the ones that happen to have the most variation in them\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The only way PCA is a valid method of feature selection is if the most important variables are the ones that happen to have the most variation in them\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674fb0f-4607-4b80-897e-0c8a9fbbf1cb",
   "metadata": {},
   "source": [
    "## Q6. What are some common applications of PCA in data science and machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa34b8b-af16-4c1d-bb72-a06aa11498e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA is used to visualize multidimensional data.\\nIt is used to reduce the number of dimensions in healthcare data.\\nPCA can help resize an image.\\nIt can be used in finance to analyze stock data and forecast returns.\\nPCA helps to find patterns in the high-dimensional datasets.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PCA is used to visualize multidimensional data.\n",
    "It is used to reduce the number of dimensions in healthcare data.\n",
    "PCA can help resize an image.\n",
    "It can be used in finance to analyze stock data and forecast returns.\n",
    "PCA helps to find patterns in the high-dimensional datasets.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7470022-2398-4a50-b327-fdda9ea18091",
   "metadata": {},
   "source": [
    "## Q7.What is the relationship between spread and variance in PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3484c357-5933-4f96-aa89-870d3acfcc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'directly proportional'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''directly proportional'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744656f2-543f-47d5-911a-43fff11e22fd",
   "metadata": {},
   "source": [
    "## Q8. How does PCA use the spread and variance of the data to identify principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee1671b-3793-4e48-8d8e-a52eb24cea8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPCA works by finding the directions of maximum variance in the data set and projecting the data onto these directions. The principal components are ordered by the amount of variance they explain and are used for feature selection, data compression, clustering, and classification\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "PCA works by finding the directions of maximum variance in the data set and projecting the data onto these directions. The principal components are ordered by the amount of variance they explain and are used for feature selection, data compression, clustering, and classification\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e28c0-e505-4423-85f2-a5f3ae7b47b9",
   "metadata": {},
   "source": [
    "## Q9. How does PCA handle data with high variance in some dimensions but low variance in others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9db7443-9c6f-4a7b-aa45-50a6e5f83656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCA generally tries to find the lower-dimensional surface to project the high-dimensional data. PCA works by considering the variance of each attribute because the high attribute shows the good split between the classes, and hence it reduces the dimensionality\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "CA generally tries to find the lower-dimensional surface to project the high-dimensional data. PCA works by considering the variance of each attribute because the high attribute shows the good split between the classes, and hence it reduces the dimensionality\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4a1bc-8645-4194-b671-34776ff5ffb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
