{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f77fb7-446e-4145-a57f-790fadbc608f",
   "metadata": {},
   "source": [
    "## Q1. What is the purpose of grid search cv in machine learning, and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaf72c9-e3b0-4299-b308-e3ba73b8d977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d0073-e97a-4e54-a25e-bacefcc6b7be",
   "metadata": {},
   "source": [
    "## Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef484b8-1ca5-4f79-9b00-ea34dfb6a818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe only difference between both the approaches is in grid search we define the combinations and do training of the model whereas in RandomizedSearchCV the model selects the combinations randomly. Both are very effective ways of tuning the parameters that increase the model generalizability.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The only difference between both the approaches is in grid search we define the combinations and do training of the model whereas in RandomizedSearchCV the model selects the combinations randomly. Both are very effective ways of tuning the parameters that increase the model generalizability.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd836055-fcf2-41b6-bb4c-efc4b5043d68",
   "metadata": {},
   "source": [
    "## Q3. What is data leakage, and why is it a problem in machine learning? Provide an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8240d3-26ef-4493-8a0a-c65e46e6ad68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIt is a situation that causes unpredictable and bad prediction outcomes after model deployment. In simple words, data leakage can be defined as: \"A scenario when ML model already has information of test data in training data, but this information would not be available at the time of prediction, called data leakage.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "It is a situation that causes unpredictable and bad prediction outcomes after model deployment. In simple words, data leakage can be defined as: \"A scenario when ML model already has information of test data in training data, but this information would not be available at the time of prediction, called data leakage.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17500a84-c667-49b3-8ec7-f394d2b3e387",
   "metadata": {},
   "source": [
    "## Q4. How can you prevent data leakage when building a machine learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1e1dc2-1e2a-4107-9a06-5ca125b8a198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOne of the best ways to get rid of data leakage is to perform k-fold cross validation where the overall data is divided into k parts. After dividing into k parts, we use each part as the cross-validation data and the remaining as training data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "One of the best ways to get rid of data leakage is to perform k-fold cross validation where the overall data is divided into k parts. After dividing into k parts, we use each part as the cross-validation data and the remaining as training data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef403e39-17b4-4253-859d-f247c3e4033a",
   "metadata": {},
   "source": [
    "## Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a9a3a6-b7ae-4d95-9c06-4e2e9b8293c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef113da-bd40-4cba-b7b7-3ac18ac0bdc7",
   "metadata": {},
   "source": [
    "## Q6. Explain the difference between precision and recall in the context of a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cced39-0c02-45d6-9041-18d41af4f48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe precision is the proportion of relevant results in the list of all returned search results. The recall is the ratio of the relevant results returned by the search engine to the total number of the relevant results that could have been returned\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The precision is the proportion of relevant results in the list of all returned search results. The recall is the ratio of the relevant results returned by the search engine to the total number of the relevant results that could have been returned\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403a938-a783-4359-b86a-081adf916b23",
   "metadata": {},
   "source": [
    "## Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b41fbfa-e5a8-4405-a675-ac3558a92bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f47c5-2990-479e-a8de-ca271ce4ff5f",
   "metadata": {},
   "source": [
    "##  Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7569fe0-5031-4b2c-883f-5b09b16b176f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConfusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7ba99-4dcf-402f-bc4b-a42319848702",
   "metadata": {},
   "source": [
    "## Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7419c7-e320-409f-ac26-d5ede9958909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\\\Here are some of the most common performance measures you can use from the confusion matrix. Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier. To calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\\Here are some of the most common performance measures you can use from the confusion matrix. Accuracy: It gives you the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier. To calculate accuracy, use the following formula: (TP+TN)/(TP+TN+FP+FN'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11cd6d-ca0b-46d6-b1b5-c9e4d7ed5aaa",
   "metadata": {},
   "source": [
    "## Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f75eed-88a7-4224-b289-82469171e15f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
