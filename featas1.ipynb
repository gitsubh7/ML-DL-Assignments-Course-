{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4291661-c795-4b41-bce1-10f02c22ff40",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90d3930-f57e-4715-ad86-7818180d58dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMany machine learning algorithms fail if the dataset contains missing values. However, algorithms like K-nearest and Naive Bayes support data with missing values. You may end up building a biased machine learning model, leading to incorrect results if the missing values are not handled properly\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Many machine learning algorithms fail if the dataset contains missing values. However, algorithms like K-nearest and Naive Bayes support data with missing values. You may end up building a biased machine learning model, leading to incorrect results if the missing values are not handled properly\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49766a-4e7c-48d5-bc10-caa80294d3ba",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c83e9-d820-4337-9ada-ee880f32c307",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Column wise deletion\n",
    "df.dropna(axis=1)\n",
    "df['Age_mean']=df['age'].fillna(df['age'].mean())\n",
    "df['age_median']=df['age'].fillna(df['age'].median())\n",
    "mode_value=df[df['embarked'].notna()]['embarked'].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d06280c-46c8-47b4-b3f8-ed862524d7f4",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd093918-73ec-4c66-92d0-ef848d9fcecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations. We can better understand imbalanced dataset handling with an example\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, i.e one class label has a very high number of observations and the other has a very low number of observations. We can better understand imbalanced dataset handling with an example\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a3ada-71f0-4513-a9c6-170a9a429040",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b47b6a8-faa4-47c0-b5e2-ac26c42037d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUp-Sampling is a \"Zero-Padding Procedure\" that increase the number of samples of a DT signal. More specificals, when up sampling, zeros are added between the samples of a signal. Down-Sampling is to decrease the sample size.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Up-Sampling is a \"Zero-Padding Procedure\" that increase the number of samples of a DT signal. More specificals, when up sampling, zeros are added between the samples of a signal. Down-Sampling is to decrease the sample size.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d34bf-63d7-455d-94a8-88154ee2e83f",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e0419d-e53d-4be4-b137-0d160d814125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSMOTE is an over-sampling technique focused on generating synthetic tabular data. The general idea of SMOTE is the generation of synthetic data between each sample of the minority class and its “k” nearest neighbors\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "SMOTE is an over-sampling technique focused on generating synthetic tabular data. The general idea of SMOTE is the generation of synthetic data between each sample of the minority class and its “k” nearest neighbors\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804899bd-3007-468d-bd53-f07dfb680631",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607d7e27-6e08-4e6a-9001-6879a9b51b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOutliers are extreme values that differ from most other data points in a dataset. They can have a big impact on your statistical analyses and skew the results of any hypothesis tests.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Outliers are extreme values that differ from most other data points in a dataset. They can have a big impact on your statistical analyses and skew the results of any hypothesis tests.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e84c6-8c0b-4bdf-9886-908bfdc6c6b9",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a554a4-cb3f-4185-8d3a-f318727e99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14bef3-b4e6-4e07-b6bf-eed2f88e3d5a",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a2fa92-ea34-4b49-92bc-3aa28b9f24f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe can down sample the datasets using the sklearn library'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "we can down sample the datasets using the sklearn library'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ed223-de8f-42a4-bfcf-01f46f69becd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
